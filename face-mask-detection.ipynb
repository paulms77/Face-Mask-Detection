{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81efec19-a77e-4035-8f29-d22363480ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import shutil\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from imutils.video import FPS\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72413525-74d8-4d23-8a69-ede233dea470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture(-1)\n",
    "\n",
    "# if not cap.isOpened():\n",
    "#     print('fail')\n",
    "#     exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa0ec8eb-ac1a-48ad-a6eb-1516bb4d990f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose([\n",
    "  transforms.Resize((224, 224)),\n",
    "  transforms.ToTensor(),\n",
    "  # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a470e77-474e-4a9a-b16f-5dfe47602d5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gimminsu/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/gimminsu/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "[W NNPACK.cpp:64] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "2024-10-11 17:25:16.953 python[30001:1187717] +[IMKClient subclass]: chose IMKClient_Legacy\n",
      "2024-10-11 17:25:16.953 python[30001:1187717] +[IMKInputSession subclass]: chose IMKInputSession_Legacy\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from imutils.video import FPS\n",
    "import imutils\n",
    "from PIL import Image\n",
    "\n",
    "def mask_detector(frame, network, model):\n",
    "    (h, w) = frame.shape[:2]\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "    network.setInput(blob)\n",
    "    detections = network.forward()\n",
    "\n",
    "    faces = []\n",
    "    locations = []\n",
    "    predictions = []\n",
    "    confidences = []\n",
    "\n",
    "    for i in range(0, detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "\n",
    "        if confidence < 0.3:\n",
    "            continue\n",
    "\n",
    "        box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "        (startX, startY, endX, endY) = box.astype(int)\n",
    "\n",
    "        startX = max(0, startX)\n",
    "        startY = max(0, startY)\n",
    "        endX = min(w - 1, endX)\n",
    "        endY = min(h - 1, endY)\n",
    "\n",
    "        if endX > startX and endY > startY:\n",
    "            face = frame[startY:endY, startX:endX]\n",
    "            \n",
    "            try:\n",
    "                face = Image.fromarray(face)\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "            face = test_transform(face)\n",
    "            face = face.unsqueeze(0).to(device)\n",
    "\n",
    "            faces.append(face)\n",
    "            locations.append((startX, startY, endX, endY))\n",
    "            confidences.append(confidence)\n",
    "\n",
    "    if len(faces) > 0:\n",
    "        with torch.no_grad():\n",
    "            predictions = model(torch.cat(faces, dim=0))\n",
    "\n",
    "    return (locations, predictions, confidences)\n",
    "\n",
    "# 모델\n",
    "face_model_path = './res10_300x300_ssd_iter_140000_fp16.caffemodel'\n",
    "prototxt_config_path = './deploy.prototxt'\n",
    "mask_detector_model_path = './best_model.pth' # mask_detector_1.pth\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # CUDA 사용\n",
    "\n",
    "# input_shape = (3, 224, 224)\n",
    "# model = CustomNet(input_shape=input_shape)\n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "model = models.mobilenet_v2(pretrained = True)\n",
    "\n",
    "# model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "model.classifier[1] = nn.Sequential(\n",
    "                      nn.Linear(1280, 256),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(256, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Dropout(0.4),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 32),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Dropout(0.4),\n",
    "                      nn.Linear(32, num_classes),\n",
    "                      nn.Softmax(dim=1))\n",
    "\n",
    "model.load_state_dict(torch.load(mask_detector_model_path, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "network = cv2.dnn.readNet(prototxt_config_path, face_model_path)\n",
    "model.to(device)\n",
    "\n",
    "# # 비디오 설정\n",
    "# video_path = './input.mov'\n",
    "# vs = cv2.VideoCapture(video_path)\n",
    "\n",
    "# # 웹캠 설정\n",
    "vs = cv2.VideoCapture(0)\n",
    "\n",
    "# 비디오 저장 설정\n",
    "videoFileName = 'output.avi'\n",
    "ret, frame = vs.read()\n",
    "\n",
    "w = int(vs.get(cv2.CAP_PROP_FRAME_WIDTH))  # width\n",
    "h = int(vs.get(cv2.CAP_PROP_FRAME_HEIGHT))  # height\n",
    "\n",
    "fps = vs.get(cv2.CAP_PROP_FPS)  # frame per second\n",
    "# fps = 25.0\n",
    "\n",
    "# avc1, mp4v, MJPG\n",
    "# *는 문자를 풀어쓰는 방식, *'DIVX' == 'D', 'I', 'V', 'X'\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "writer = cv2.VideoWriter(videoFileName, fourcc, fps, (w, h), True)\n",
    "\n",
    "# fps = FPS().start()\n",
    "\n",
    "# writer = None\n",
    "\n",
    "if vs.isOpened():\n",
    "    while True:\n",
    "        ret, frame = vs.read()\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # 좌우 반전\n",
    "        if ret:\n",
    "            frame = cv2.flip(frame, 1)\n",
    "            \n",
    "        frame = imutils.resize(frame, width=500)\n",
    "        \n",
    "        if frame is None:\n",
    "            break\n",
    "\n",
    "        (locations, predicts, confidences) = mask_detector(frame, network, model)\n",
    "\n",
    "        for (box, predict, confidence) in zip(locations, predicts, confidences):\n",
    "            (startX, startY, endX, endY) = box\n",
    "            (without_mask, mask) = predict\n",
    "            confidence_label = confidence\n",
    "\n",
    "            label = \"No Mask\" if mask > without_mask else \"Mask\"\n",
    "\n",
    "            if label == \"Mask\" and max(mask, without_mask) * 100 >= 70:\n",
    "                color = (0, 255, 0)  # 초록\n",
    "            elif label == \"No Mask\" and max(mask, without_mask) * 100 >= 70:\n",
    "                color = (0, 0, 255)  # 빨강\n",
    "            else:\n",
    "                color = (0, 0, 255)  # 부적절한 마스크도 미착용(No Mask)에 포함\n",
    "\n",
    "            label = \"{}: {:.2f}%\".format(label, max(mask, without_mask) * 100)\n",
    "\n",
    "            cv2.putText(frame, label, (startX, startY - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 2, cv2.LINE_AA)\n",
    "            # cv2.putText(frame, f'Confidence: {confidence_label:.2f}', (startX, startY - 30), cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 2, cv2.LINE_AA)\n",
    "            cv2.rectangle(frame, (startX, startY), (endX, endY), thickness=2, color=color)\n",
    "            \n",
    "        # ESC키 누르면 중지\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "        \n",
    "        # fps.update()\n",
    "        \n",
    "        # if writer is None:\n",
    "        #     # *는 문자를 풀어쓰는 방식, *'DIVX' == 'D', 'I', 'V', 'X'\n",
    "        #     fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        #     writer = cv2.VideoWriter(videoFileName, fourcc, fps, (w, h), True)\n",
    "\n",
    "        #비디오 저장\n",
    "        if writer is not None:\n",
    "            writer.write(frame)\n",
    "            \n",
    "        cv2.imshow(\"Mask Detector\", frame)\n",
    "        \n",
    "else:\n",
    "    print('not opened')\n",
    "\n",
    "# # # fps 정지 및 정보 출력\n",
    "# fps.stop()\n",
    "# print(\"[재생 시간 : {:.2f}초]\".format(fps.elapsed()))\n",
    "# print(\"[FPS : {:.2f}]\".format(fps.fps()))\n",
    "\n",
    "# 종료\n",
    "writer.release()\n",
    "vs.release()\n",
    "cv2.destroyAllWindows()\n",
    "exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d47f0f5e-2005-4edd-81f4-c0241ed5ec4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.10.0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.__version__\n",
    "# 4.10.0.84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e066387-7fe5-456b-a429-fa48a9f66c19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f01cc05-3ba2-4ba8-bfce-72306c1cc66e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
