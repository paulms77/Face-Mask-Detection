{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c07cccc-2a76-4cfd-b280-dfabc4251d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "import gc\n",
    "import shutil\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c358679-3e74-431e-9ad5-e7cd352be0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5492f3b-1c37-431a-ae0f-6a35953a0cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = '/content/drive/MyDrive/mask'\n",
    "batch_size = 32\n",
    "init_learning_rate = 0.0001\n",
    "epochs = 10\n",
    "model_name = 'mask_detector_large.pth'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # CUDA가 사용 가능한 경우 GPU 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6626d9-4008-41de-bdda-5eddf7110d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "  transforms.RandomRotation(degrees = 15),\n",
    "  transforms.RandomHorizontalFlip(),\n",
    "  # transforms.RandomAffine(degrees = 0, shear = 0.2),\n",
    "  transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "  # transforms.RandomPerspective(distortion_scale=0.2),\n",
    "  # transforms.RandomAffine(degrees=0, translate=(0.2, 0.2)),\n",
    "\n",
    "  transforms.Resize((224, 224)),\n",
    "  transforms.ToTensor(),\n",
    "  # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "  transforms.Resize((224, 224)),\n",
    "  transforms.ToTensor(),\n",
    "  # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(root = dataset_dir, transform=train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54257d30-6815-4eeb-a0c2-6d0587d27fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1ab12f-1861-49db-aeb7-8fc5d25e69f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = dataset.classes # ['combined_with_mask', 'combined_without_mask']\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bfb5f0-cf2d-4916-ac38-809986c7188e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_counting = {}\n",
    "for label in classes:\n",
    "  class_path = os.path.join(dataset_dir, label)\n",
    "  image_counting[label] = len(os.listdir(class_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141476d9-04d5-4911-bcc5-9f05a46528a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6963ff70-b383-4ed0-91b7-05280279f4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * (len(dataset)))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "test_dataset.dataset.transform = test_transform\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle = False, num_workers=4)\n",
    "\n",
    "model = models.mobilenet_v2(pretrained = True)\n",
    "num_classes = 2\n",
    "# model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "model.classifier[1] = nn.Sequential(\n",
    "                      nn.Linear(1280, 256),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(256, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Dropout(0.4),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 32),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Dropout(0.4),\n",
    "                      nn.Linear(32, num_classes),\n",
    "                      nn.Softmax(dim=1))\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = init_learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9c3512-c009-4b36-97c2-ee79b3569dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  model.train()\n",
    "  train_loss = 0.0\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  train_bar = tqdm(train_loader, desc = 'Training', total = len(train_loader), leave=False)\n",
    "\n",
    "  for inputs, labels in train_bar:\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    train_loss += loss.item()\n",
    "    predicted = torch.argmax(outputs, axis = 1)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "    total += labels.size(0)\n",
    "\n",
    "    train_bar.set_postfix(Train_loss = train_loss/len(train_loader), Train_acc = correct/total)\n",
    "\n",
    "  train_losses.append(train_loss / len(train_loader))\n",
    "  train_accuracies.append(correct / total)\n",
    "\n",
    "  torch.cuda.empty_cache()\n",
    "  gc.collect()\n",
    "\n",
    "  model.eval()\n",
    "  val_loss = 0.0\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  test_bar = tqdm(test_loader, desc = 'Validing', total = len(test_loader), leave=False)\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for inputs, labels in test_bar:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        val_loss += loss.item()\n",
    "        predicted = torch.argmax(outputs, axis = 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        test_bar.set_postfix(val_loss = val_loss/len(test_loader), val_acc = correct/total)\n",
    "\n",
    "  val_losses.append(val_loss / len(test_loader))\n",
    "  val_accuracies.append(correct / total)\n",
    "\n",
    "  print(f'Epoch [{epoch + 1}/{epochs}], Train Loss: {train_losses[-1]:.4f}, Train Accuracy: {train_accuracies[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}, Val Accuracy: {val_accuracies[-1]:.4f}')\n",
    "\n",
    "torch.save(model.state_dict(), model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e76be4-c229-4cba-86e8-71c65a146024",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, epochs), train_losses, label = 'train loss')\n",
    "plt.plot(np.arange(0, epochs), val_losses, label = 'train loss')\n",
    "plt.plot(np.arange(0, epochs), train_accuracies, label = 'train acc')\n",
    "plt.plot(np.arange(0, epochs), val_accuracies, label = 'val acc')\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "\n",
    "plt.savefig('result_plot.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3420b3ad-16f9-4c1b-941b-196ca4a70b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "  for inputs, labels in test_loader:\n",
    "    inputs = inputs.to(device)\n",
    "    outputs = model(inputs)\n",
    "    preds = torch.argmax(outputs, axis = 1)\n",
    "    all_labels.extend(labels.cpu().numpy())\n",
    "    all_preds.extend(preds.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16252c34-3e67-40dc-b5e3-0ec5936b5c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of all_labels:', np.array(all_labels).shape)\n",
    "print('Shape of all_preds:', np.array(all_preds).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641cc07b-5ad7-4400-9298-a61e9dec10b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(np.array(all_labels), np.array(all_preds)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
